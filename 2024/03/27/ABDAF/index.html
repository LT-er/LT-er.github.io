

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/icon.jpg">
  <link rel="icon" href="/img/icon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="theme-color" content="#181c27">
  <meta name="author" content="LT">
  <meta name="keywords" content="">
  
    <meta name="description" content="笔试题目 数据描述： 哈佛大学从中国的古代人物传记中整理出515,488人的信息，构建了中国历代人物传记资料库（CBDB）。时间跨度约为7世界至19世纪，收集了史料中记载的历史人物的基本信息、社会关系和入仕情况等数据，使用该数据集可以用于群体传记学的统计、网络和空间分析。“由人物（People）、親屬（Kinship）、非親屬社會關係（Non-kinship Associations）、社會區分（">
<meta property="og:type" content="article">
<meta property="og:title" content="基于中國歷代人物傳記資料庫(CBDB)的数据分析与挖掘">
<meta property="og:url" content="http://example.com/2024/03/27/ABDAF/index.html">
<meta property="og:site_name" content="LTSpace">
<meta property="og:description" content="笔试题目 数据描述： 哈佛大学从中国的古代人物传记中整理出515,488人的信息，构建了中国历代人物传记资料库（CBDB）。时间跨度约为7世界至19世纪，收集了史料中记载的历史人物的基本信息、社会关系和入仕情况等数据，使用该数据集可以用于群体传记学的统计、网络和空间分析。“由人物（People）、親屬（Kinship）、非親屬社會關係（Non-kinship Associations）、社會區分（">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/image-20240326110031171.png">
<meta property="og:image" content="http://example.com/images/image-20240326110234737.png">
<meta property="og:image" content="http://example.com/images/image-20240326123402946.png">
<meta property="og:image" content="http://example.com/images/image-20240326135102496.png">
<meta property="og:image" content="http://example.com/images/image-20240326140525978.png">
<meta property="og:image" content="http://example.com/images/image-20240326144051417.png">
<meta property="og:image" content="http://example.com/images/image-20240326144144022.png">
<meta property="og:image" content="http://example.com/images/image-20240326144332774.png">
<meta property="og:image" content="http://example.com/images/image-20240326162543188.png">
<meta property="og:image" content="http://example.com/images/image-20240326153606310.png">
<meta property="og:image" content="http://example.com/images/image-20240326221907003.png">
<meta property="og:image" content="http://example.com/images/image-20240326230505887.png">
<meta property="og:image" content="http://example.com/images/image-20240326233039131.png">
<meta property="article:published_time" content="2024-03-27T03:35:15.000Z">
<meta property="article:modified_time" content="2024-03-27T04:46:13.221Z">
<meta property="article:author" content="LT">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/images/image-20240326110031171.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>基于中國歷代人物傳記資料庫(CBDB)的数据分析与挖掘 - LTSpace</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":60,"cursorChar":"_","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 7.1.1"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>LT&#39;s space</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/back1.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">基于中國歷代人物傳記資料庫(CBDB)的数据分析与挖掘</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-03-27 11:35" pubdate>
          2024年3月27日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          61 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">基于中國歷代人物傳記資料庫(CBDB)的数据分析与挖掘</h1>
            
            
              <div class="markdown-body">
                
                <h1>笔试题目</h1>
<h2 id="数据描述：">数据描述：</h2>
<p>哈佛大学从中国的古代人物传记中整理出515,488人的信息，构建了<a target="_blank" rel="noopener" href="https://projects.iq.harvard.edu/chinesecbdb">中国历代人物传记资料库</a>（CBDB）。时间跨度约为7世界至19世纪，收集了史料中记载的历史人物的基本信息、社会关系和入仕情况等数据，使用该数据集可以用于群体传记学的统计、网络和空间分析。“由人物（People）、親屬（Kinship）、非親屬社會關係（Non-kinship Associations）、社會區分（Status）、入仕途徑（Modes of Entry into Government）、宦歷（Offices / Postings）、地址（Places）、著述（Writings）等部份組成。”</p>
<h2 id="数据分析：">数据分析：</h2>
<p>根据自己的理解，对数据进行分析和挖掘。本题是开放式的，具体的分析内容可以基于你的观察和思考，我们对此没有任何的限制，鼓励你进行自己的思考。抛砖引玉的一些想法：比如古代的婚姻关系是否以家族为中心，教育水平是否存在区域和阶级差异，科举体制中是否存在“小镇做题家“，中国历史上是否存在阶层固化。也可以进行预测性建模。请发挥想象力进行有趣的分析，进行可视化结果展示。</p>
<h2 id="数据建模：">数据建模：</h2>
<p>我们需要你完成预测性建模。你可以选择你感兴趣的点进行建模，也可以选择完成以下的问题：ENTRY_DATA中记载了历史人物的入仕情况，请结合整个数据表信息预测人物是否入仕，并对结果进行相应的分析和解读。</p>
<p>请提交处理和<strong>分析代码以及报告</strong>，报告内容可以参考一般论文或数据挑战notebook的形式，汇报分析与建模的结果与发现，截止日期为3.28周四晚上23:59。</p>
<h2 id="Resource：">Resource：</h2>
<p>l 数据下载：<br>
<a target="_blank" rel="noopener" href="https://projects.iq.harvard.edu/chinesecbdb/%E4%B8%8B%E8%BC%89cbdb%E5%96%AE%E6%A9%9F%E7%89%88">https://projects.iq.harvard.edu/chinesecbdb/%E4%B8%8B%E8%BC%89cbdb%E5%96%AE%E6%A9%9F%E7%89%88</a></p>
<p>l 数据详细描述：<br>
<a target="_blank" rel="noopener" href="https://projects.iq.harvard.edu/files/cbdb/files/cbdb_users_guide_ch_20210322.pdf">https://projects.iq.harvard.edu/files/cbdb/files/cbdb_users_guide_ch_20210322.pdf</a></p>
<p>l 数据表链接关系：<br>
<a target="_blank" rel="noopener" href="https://docs.qq.com/sheet/DZWdLeGNlYkNtQnh1?tab=000001">https://docs.qq.com/sheet/DZWdLeGNlYkNtQnh1?tab=000001</a></p>
<h1>分析过程</h1>
<h2 id="预先准备">预先准备</h2>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/370633306">【3天速成QGIS】第1讲_QGIS下载安装+中文配置+加载底图 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://i.youku.com/i/UMzI5NTM5MDAwNA==">CBDB_video的自频道-优酷视频 (youku.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://projects.iq.harvard.edu/chinesecbdb/%E4%B8%8B%E8%BC%89%E6%95%99%E5%AD%B8%E8%88%87%E8%BC%94%E5%8A%A9%E6%96%87%E4%BB%B6">教學與輔助文件 | 中國歷代人物傳記資料庫（CBDB） (harvard.edu)</a></p>
<p>下载sqlite版CBDB数据，选择navicat图形化界面进行数据查询</p>
<p>通读数据详细描述，梳理数据库脉络，选择试用QGIS，Pajek进行数据图形化表示，</p>
<p>Pajek需要自己写脚本手动生成边，放弃</p>
<p>根据《置身事内》《沧浪之水》《金榜题名之后》三本书以及题目提示，提出三个数据分析题目</p>
<p>通读数据表链接关系</p>
<p>尝试结合AAAI论文<a target="_blank" rel="noopener" href="https://faculty.sist.shanghaitech.edu.cn/zhanghp/papers/aaai23gender_guessing.pdf">&quot;For the Underrepresented in Gender Bias Research: Chinese Name Gender Prediction with Heterogeneous Graph Attention Network.&quot;</a> 进行古代女性名称数据预测建模，寻找开源代码</p>
<p><a target="_blank" rel="noopener" href="https://github.com/ZhangDataLab/CHGAT">ZhangDataLab/CHGAT: The code for paper “For the Underrepresented in Gender Bias Research: Chinese Name Gender Prediction with Heterogeneous Graph Attention Network” in AAAI2023. (github.com)</a></p>
<p>尝试训练，但本地win平台1gpu需要改动的代码太多，放弃</p>
<h2 id="数据分析：-2">数据分析：</h2>
<h3 id="寒门士子到世家子弟的仕途轨迹比较">寒门士子到世家子弟的仕途轨迹比较</h3>
<h4 id="世家子弟查询">世家子弟查询</h4>
<p>选出ENTRY_TYPES表中c_entry_type_sortorder=2or3 or 4 or 7or 9 or 13的对应的c_entry_type， 根据选出的c_entry_type去ENTRY_CODE_TYPE_REL中选出c_entry_type对应的c_entry_code，再根据选出的c_entry_code去ENTRY_DATA中选出对应的c_pensonid</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">-- 选择ENTRY_TYPES表中满足条件的c_entry_type<br>SELECT c_entry_type<br>FROM ENTRY_TYPES<br>WHERE c_entry_type_sortorder IN (2, 3, 4, 7, 9, 13);<br><br>-- 使用子查询获取ENTRY_CODE_TYPE_REL中对应的c_entry_code<br>SELECT ect.c_entry_code<br>FROM ENTRY_CODE_TYPE_REL AS ect<br>WHERE ect.c_entry_type IN (<br>    SELECT et.c_entry_type<br>    FROM ENTRY_TYPES AS et<br>    WHERE et.c_entry_type_sortorder IN (2, 3, 4, 7, 9, 13)<br>);<br><br>-- 最后，使用子查询获取ENTRY_DATA中对应的c_pensonid<br>SELECT ed.c_personid<br>FROM ENTRY_DATA AS ed<br>WHERE ed.c_entry_code IN (<br>    SELECT ect.c_entry_code<br>    FROM ENTRY_CODE_TYPE_REL AS ect<br>    WHERE ect.c_entry_type IN (<br>        SELECT et.c_entry_type<br>        FROM ENTRY_TYPES AS et<br>        WHERE et.c_entry_type_sortorder IN (2, 3, 4, 7, 9, 13)<br>    )<br>);<br></code></pre></td></tr></table></figure>
<p><img src="/images/image-20240326110031171.png" srcset="/img/loading.gif" lazyload alt="image-20240326110031171"></p>
<p>共5338条符合条件的世家子弟</p>
<h4 id="寒门子弟查询">寒门子弟查询</h4>
<p>先找出通过正常科举的<br>
即需要c_entry_type_sortorder = 17</p>
<p><img src="/images/image-20240326110234737.png" srcset="/img/loading.gif" lazyload alt="image-20240326110234737"></p>
<p>再进行三代以内的亲属排除筛选</p>
<p>KINSHIP_CODES表中，</p>
<p>將親屬向上的代數限制（c_upstep）設置為2（即小於3. 例如，FF，FFB等）<br>
將親屬向下的代數限制（c_upstep）設置為0（也就是說我們只想查看長輩親屬）<br>
將姻親關係限制（c_marstep）設置為0<br>
將兄弟姐妹關係限制（c_colstep）設置為最多為1 （即小於2）</p>
<p>启发来自于CBDB数据详细描述pdf</p>
<p>选出满足这些关系的对应的c_kincode</p>
<p>再去KIN_DATA表中，</p>
<p>选出KIN_DATA表中满足c_kin_code等于KINSHIP_CODES表中选出的c_kincode的c_personid</p>
<p>根据c_personid再去POSTIGN_DATA中查询是否有c_posting_id</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">-- 找出那些没有三代内亲戚做官的人的 c_personid<br>WITH NoOfficialRelatives AS (<br>    SELECT DISTINCT ed.c_personid<br>    FROM ENTRY_DATA AS ed<br>    WHERE ed.c_personid NOT IN (<br>        SELECT p.c_personid<br>        FROM POSTING_DATA AS p<br>        JOIN KIN_DATA AS kd ON p.c_personid = kd.c_personid<br>        JOIN KINSHIP_CODES AS kc ON kd.c_kin_code = kc.c_kincode<br>        WHERE kc.c_upstep &lt;= 2 AND kc.c_dwnstep = 0 AND kc.c_marstep = 0 AND kc.c_colstep &lt; 2<br>    )<br>)<br><br>-- 找出 c_entry_type_sortorder 为 17 的人<br>, OfficialsWithOrder17 AS (<br>    SELECT ed.c_personid<br>    FROM ENTRY_DATA AS ed<br>    JOIN ENTRY_CODE_TYPE_REL AS ectrel ON ed.c_entry_code = ectrel.c_entry_code<br>    JOIN ENTRY_TYPES AS et ON ectrel.c_entry_type = et.c_entry_type<br>    WHERE et.c_entry_type_sortorder = 17<br>)<br><br>-- 找出同时满足上述两个条件的人<br>SELECT *<br>FROM NoOfficialRelatives<br>INTERSECT<br>SELECT c_personid<br>FROM OfficialsWithOrder17;<br></code></pre></td></tr></table></figure>
<p><img src="/images/image-20240326123402946.png" srcset="/img/loading.gif" lazyload alt="image-20240326123402946"></p>
<p>选出四千七百个寒门子弟</p>
<h4 id="挑出这些人的officetreeid">挑出这些人的officetreeid</h4>
<p>在POSTED_TO_OFFICE_DATA里，c_personid可对应c_office_id，</p>
<p>在OFFICE_CODE_TYPE_REL里，c_office_id可对应c_office_tree_id，c_office_tree_id的位数越小，归属的局越高</p>
<p>在OFFICE_TYPE_TREE里，c_office_type_node_id对应官职部门的中文词条，可以做词云等</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">-- 找出那些没有三代内亲戚做官的人的 c_personid<br>WITH NoOfficialRelatives AS (<br>    SELECT DISTINCT ed.c_personid<br>    FROM ENTRY_DATA AS ed<br>    WHERE ed.c_personid NOT IN (<br>        SELECT p.c_personid<br>        FROM POSTING_DATA AS p<br>        JOIN KIN_DATA AS kd ON p.c_personid = kd.c_personid<br>        JOIN KINSHIP_CODES AS kc ON kd.c_kin_code = kc.c_kincode<br>        WHERE kc.c_upstep &lt;= 2 AND kc.c_dwnstep = 0 AND kc.c_marstep = 0 AND kc.c_colstep &lt; 2<br>    )<br>)<br><br>-- 找出 c_entry_type_sortorder 为 17 的人<br>, OfficialsWithOrder17 AS (<br>    SELECT ed.c_personid<br>    FROM ENTRY_DATA AS ed<br>    JOIN ENTRY_CODE_TYPE_REL AS ectrel ON ed.c_entry_code = ectrel.c_entry_code<br>    JOIN ENTRY_TYPES AS et ON ectrel.c_entry_type = et.c_entry_type<br>    WHERE et.c_entry_type_sortorder = 17<br>)<br><br>-- 找出同时满足上述两个条件的人<br>, EligibleOfficials AS (<br>    SELECT c_personid<br>    FROM NoOfficialRelatives<br>    INTERSECT<br>    SELECT c_personid<br>    FROM OfficialsWithOrder17<br>)<br><br>-- 查询这些寒门子弟的官职信息以及对应的 office_tree_id<br>SELECT pto.c_office_id, octr.c_office_tree_id<br>FROM EligibleOfficials AS ef<br>JOIN POSTED_TO_OFFICE_DATA AS pto ON ef.c_personid = pto.c_personid<br>JOIN OFFICE_CODE_TYPE_REL AS octr ON pto.c_office_id = octr.c_office_id<br>WHERE octr.c_office_tree_id &lt;&gt; 20;<br></code></pre></td></tr></table></figure>
<p><img src="/images/image-20240326135102496.png" srcset="/img/loading.gif" lazyload alt="image-20240326135102496"></p>
<p>排除20是因为20是清朝，录入后的清朝数据的官位都是20，不符合条件</p>
<p>世家子弟有三万条</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">-- 获取不包含c_office_tree_id为20的c_office_id和c_office_tree_id<br>SELECT pod.c_office_id, octr.c_office_tree_id<br>FROM POSTED_TO_OFFICE_DATA AS pod<br>JOIN OFFICE_CODE_TYPE_REL AS octr ON pod.c_office_id = octr.c_office_id<br>WHERE pod.c_personid IN (<br>    SELECT ed.c_personid<br>    FROM ENTRY_DATA AS ed<br>    WHERE ed.c_entry_code IN (<br>        SELECT ect.c_entry_code<br>        FROM ENTRY_CODE_TYPE_REL AS ect<br>        WHERE ect.c_entry_type IN (<br>            SELECT et.c_entry_type<br>            FROM ENTRY_TYPES AS et<br>            WHERE et.c_entry_type_sortorder IN (2, 3, 4, 7, 9, 13)<br>        )<br>    )<br>)<br>AND octr.c_office_tree_id != 20;<br></code></pre></td></tr></table></figure>
<p><img src="/images/image-20240326140525978.png" srcset="/img/loading.gif" lazyload alt="image-20240326140525978"></p>
<h4 id="python脚本进行数据可视化">python脚本进行数据可视化</h4>
<h5 id="柱状图绘制：">柱状图绘制：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 读取CSV文件</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;寒门子弟职位归属.csv&#x27;</span>)<br><br><span class="hljs-comment"># 将c_office_tree_id列转换为字符串类型</span><br>df[<span class="hljs-string">&#x27;c_office_tree_id&#x27;</span>] = df[<span class="hljs-string">&#x27;c_office_tree_id&#x27;</span>].astype(<span class="hljs-built_in">str</span>)<br><br><span class="hljs-comment"># 计算每个c_office_tree_id长度的人数</span><br>office_counts_by_length = df[<span class="hljs-string">&#x27;c_office_tree_id&#x27;</span>].<span class="hljs-built_in">str</span>.<span class="hljs-built_in">len</span>().value_counts()<br><br><span class="hljs-comment"># 筛选出人数排名前十的职位长度</span><br>top_ten_lengths = office_counts_by_length.head(<span class="hljs-number">10</span>)<br><br><span class="hljs-comment"># 绘制柱状图</span><br>plt.figure(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">6</span>))<br>bars = plt.bar(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(top_ten_lengths)), top_ten_lengths.values, color=<span class="hljs-string">&#x27;skyblue&#x27;</span>)<br><br><span class="hljs-comment"># 在每个柱子上方添加具体的人数数字</span><br><span class="hljs-keyword">for</span> i, bar <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(bars):<br>    plt.text(i, bar.get_height() + <span class="hljs-number">0.1</span>, <span class="hljs-built_in">str</span>(top_ten_lengths.values[i]), ha=<span class="hljs-string">&#x27;center&#x27;</span>, va=<span class="hljs-string">&#x27;bottom&#x27;</span>)<br><br>plt.xticks(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(top_ten_lengths)), top_ten_lengths.index, rotation=<span class="hljs-number">90</span>)<br>plt.title(<span class="hljs-string">&#x27;Top 10 Position Lengths by Number of Poor People&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&#x27;Position ID Length&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;Number of People&#x27;</span>)<br>plt.tight_layout()<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="/images/image-20240326144051417.png" srcset="/img/loading.gif" lazyload alt="image-20240326144051417"></p>
<p><img src="/images/image-20240326144144022.png" srcset="/img/loading.gif" lazyload alt="image-20240326144144022"></p>
<h5 id="平均官位级别计算">平均官位级别计算</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> csv<br><br><span class="hljs-comment"># 定义一个函数来计算CSV文件的行数和c_office_tree_id的平均位数</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">calculate_csv_stats</span>(<span class="hljs-params">csv_file</span>):<br>    total_rows = <span class="hljs-number">0</span><br>    total_digits = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(csv_file, mode=<span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> file:<br>        reader = csv.reader(file)<br>        <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> reader:<br>            total_rows += <span class="hljs-number">1</span><br>            <span class="hljs-comment"># 假设c_office_tree_id是每行的最后一个字段</span><br>            tree_id = row[-<span class="hljs-number">1</span>]<br>            <span class="hljs-comment"># 计算c_office_tree_id的位数，忽略首尾的空格</span><br>            tree_id_digits = <span class="hljs-built_in">len</span>(tree_id.strip()) <span class="hljs-keyword">if</span> tree_id.strip() <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>            total_digits += tree_id_digits<br>    <span class="hljs-comment"># 计算平均位数</span><br>    average_digits = total_digits / total_rows <span class="hljs-keyword">if</span> total_rows &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> total_rows, average_digits<br><br><span class="hljs-comment"># 计算世家子弟职位归属.csv的行数和c_office_tree_id的平均位数</span><br>gentry_file_stats = calculate_csv_stats(<span class="hljs-string">&#x27;世家子弟职位归属.csv&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;世家子弟职位归属.csv - 行数: <span class="hljs-subst">&#123;gentry_file_stats[<span class="hljs-number">0</span>]&#125;</span>, 平均位数: <span class="hljs-subst">&#123;gentry_file_stats[<span class="hljs-number">1</span>]:<span class="hljs-number">.2</span>f&#125;</span>&#x27;</span>)<br><br><span class="hljs-comment"># 计算寒门子弟职位归属.csv的行数和c_office_tree_id的平均位数</span><br>commoner_file_stats = calculate_csv_stats(<span class="hljs-string">&#x27;寒门子弟职位归属.csv&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;寒门子弟职位归属.csv - 行数: <span class="hljs-subst">&#123;commoner_file_stats[<span class="hljs-number">0</span>]&#125;</span>, 平均位数: <span class="hljs-subst">&#123;commoner_file_stats[<span class="hljs-number">1</span>]:<span class="hljs-number">.2</span>f&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<p><img src="/images/image-20240326144332774.png" srcset="/img/loading.gif" lazyload alt="image-20240326144332774"></p>
<h3 id="古代中国官员地域背景与地方经济政策的不平衡影响">古代中国官员地域背景与地方经济政策的不平衡影响</h3>
<p>计算进士来自于哪个地方</p>
<p>在ENTRY_DATA表里选中c_entry_code=36，即入仕方式为进士的人，提取他们的个人id c_personid，根据个人id去BLOG_ADDR_DATA表中找到c_addr_id，根据c_addr_id在ADDRESSES中找到c_name_chn	地址中文名称 ，x_coord	x轴，y_coord	y轴，belongs1_ID	第一层从属行政区ID belongs1_Name	第一层从属行政区名称 belongs2_ID	第二层从属行政区ID belongs2_Name	第二层从属行政区名称</p>
<p>把结果按照个人id聚合，</p>
<p><img src="/images/image-20240326162543188.png" srcset="/img/loading.gif" lazyload alt="image-20240326162543188"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">SELECT <br>    ed.c_personid AS 个人ID,<br>    a.c_name_chn AS 地址中文名称,<br>    a.x_coord AS x轴,<br>    a.y_coord AS y轴,<br>    a.belongs1_ID AS 第一层从属行政区ID,<br>    a.belongs1_Name AS 第一层从属行政区名称,<br>    a.belongs2_ID AS 第二层从属行政区ID,<br>    a.belongs2_Name AS 第二层从属行政区名称<br>FROM <br>    ENTRY_DATA ed<br>INNER JOIN <br>    BIOG_ADDR_DATA bad ON ed.c_personid = bad.c_personid<br>INNER JOIN <br>    ADDRESSES a ON bad.c_addr_id = a.c_addr_id<br>WHERE <br>    ed.c_entry_code = 36<br>GROUP BY <br>    ed.c_personid;<br></code></pre></td></tr></table></figure>
<p>导入QGIS</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/googlegis/p/14986844.html">在QGIS加载天地图、高德地图 - googlegis - 博客园 (cnblogs.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/353888644">【花式GIS】QGIS加地图服务 - 知乎 (zhihu.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://www.osgeo.cn/qgis-tutorial/docs/3/importing_spreadsheets_csv.html">导入电子表格或CSV文件（QGIS3） — QGIS Tutorials and Tips (osgeo.cn)</a></p>
<p><strong>如果gis导入地图和csv文件后仍然一直空白，应该是sans字体无法加载下载失败或者timeout，打开代理的TUN模式，重启QGIS即可</strong></p>
<h3 id="大型团体事务中地域同乡、与血缘亲缘关系的交织影响">大型团体事务中地域同乡、与血缘亲缘关系的交织影响</h3>
<p>表中进行top1之后发现事务代码51的事务在其中参与者最多，选用事务代码51的事件进行研究</p>
<p>sqlite数据库中，EVENTS_DATA表，选出c_event_code=51的c_personid，去KIN_DATA中根据c_personid个人id 找出所有的c_kin_id亲属的id，和c_kin_code关系类别的代码 亲属id到BIOG_MAIN表中=c_personid找出他的c_name_chn显示出来；c_kin_code去KINSHIP_CODES中=c_kincode，找到对应的c_kinrel_chn中文名显示出来</p>
<p><img src="/images/image-20240326153606310.png" srcset="/img/loading.gif" lazyload alt="image-20240326153606310"></p>
<h2 id="数据建模">数据建模</h2>
<h3 id="数据处理">数据处理</h3>
<p>人工筛选，识别并提取出数据表中对历史人物是否入仕具有显著影响的关键因素</p>
<p><img src="/images/image-20240326221907003.png" srcset="/img/loading.gif" lazyload alt="image-20240326221907003"></p>
<h4 id="选出人工筛选后的所有列">选出人工筛选后的所有列</h4>
<p>将表中的属性提取出来，形成一个表，把列名改为中文名，应该从ENTRY_DATA中查出c_kin_id亲属的id，再让POSTED_TO_OFFICE_DATA中c_kin_id=c_personid，查出亲戚的官职c_posting_id</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">SELECT<br>  BM.c_personid AS &#x27;个人ID&#x27;,<br>  BM.c_female AS &#x27;是否为女性&#x27;,<br>--   BM.c_household_status_code AS &#x27;所属户籍代码&#x27;,<br>  BM.c_dy AS &#x27;朝代&#x27;,<br>  BM.c_choronym_code AS &#x27;郡望代码&#x27;,<br>  BM.c_index_addr_id AS &#x27;地址ID&#x27;,<br>  PO.c_office_id AS &#x27;官署ID&#x27;,<br>  PO.c_posting_id AS &#x27;官职ID&#x27;,<br>  -- 使用子查询获取亲属的官职ID<br>--   (SELECT PO2.c_posting_id FROM POSTED_TO_OFFICE_DATA PO2 WHERE PO2.c_personid = ED.c_kin_id) AS &#x27;亲属官职ID&#x27;,<br>--   PO.c_assume_office_code AS &#x27;是否赴任代码&#x27;,<br>  ED.c_entry_code AS &#x27;入仕方式代码&#x27;,<br>  ED.c_exam_rank AS &#x27;考试名次&#x27;,<br>--   ED.c_kin_code AS &#x27;考官亲属关系&#x27;,<br>--   ED.c_kin_id AS &#x27;亲属ID&#x27;,<br>  ED.c_age AS &#x27;入仕年龄&#x27;<br>--   ED.c_attempt_count AS &#x27;考试尝试次数&#x27;<br>FROM<br>  BIOG_MAIN BM<br>JOIN<br>  ENTRY_DATA ED ON BM.c_personid = ED.c_personid<br>LEFT JOIN<br>  POSTED_TO_OFFICE_DATA PO ON BM.c_personid = PO.c_personid<br>WHERE<br>  ED.c_kin_id IS NOT NULL;<br></code></pre></td></tr></table></figure>
<p>再聚合每个人的信息，以便每个人的信息只出现一次，使用<code>GROUP BY</code>子句来对<code>c_personid</code>进行分组，并选择每个分组的代表性记录。使用<code>MAX</code>函数来选择每个个人的最新官职记录，假设<code>c_posting_id</code>是可以用来判断官职新旧的字段。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">DROP TABLE 结果表;<br>CREATE TABLE 结果表 AS<br>SELECT<br>  BM.c_personid AS &#x27;个人ID&#x27;,<br>  BM.c_female AS &#x27;是否为女性&#x27;,<br>  BM.c_household_status_code AS &#x27;所属户籍代码&#x27;,<br>  BM.c_dy AS &#x27;朝代&#x27;,<br>  BM.c_choronym_code AS &#x27;郡望&#x27;,<br>  BM.c_index_addr_id AS &#x27;地址ID&#x27;,<br>  MAX(PTOD.c_office_id) AS &#x27;官署ID&#x27;,<br>  MAX(PTOD.c_posting_id) AS &#x27;官职ID&#x27;,<br>  ED.c_entry_code AS &#x27;入仕方式代码&#x27;,<br>  ED.c_exam_rank AS &#x27;考试名次&#x27;,<br>  ED.c_age AS &#x27;入仕时的年龄&#x27;<br>FROM <br>  (SELECT * FROM BIOG_MAIN ORDER BY c_personid) BM<br>LEFT JOIN <br>  (SELECT * FROM ENTRY_DATA ORDER BY c_personid) ED ON BM.c_personid = ED.c_personid<br>LEFT JOIN <br>  (SELECT c_personid, MAX(c_office_id) as c_office_id, MAX(c_posting_id) as c_posting_id FROM POSTED_TO_OFFICE_DATA GROUP BY c_personid) PTOD ON BM.c_personid = PTOD.c_personid<br>GROUP BY BM.c_personid;<br></code></pre></td></tr></table></figure>
<h4 id="处理缺失值">处理缺失值</h4>
<p>c_attempt_count  考试尝试次数缺失值过多，删去</p>
<p>c_exam_rank  考试名次缺失值过多，删去</p>
<p>c_assume_office_code  个人是否赴任的代码缺失值过多，删去</p>
<p>c_kin_code  考官与其是否有亲属关系缺失值过多，删去</p>
<p>缺省的朝代填充19 地址缺省过多，删除缺省地址数据</p>
<p>地址id替换为地址对应的省id，增强相关性</p>
<p>按照官职官署id如果都为0时标注为没有入仕，其他标注为1入仕，所以官职官署id对于是否入仕的影响太强，drop</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs sqlite">CREATE TABLE 结果表 AS<br>SELECT<br>  BM.c_personid AS &#x27;个人ID&#x27;,<br>  BM.c_female AS &#x27;是否为女性&#x27;,<br>  BM.c_dy AS &#x27;朝代&#x27;,<br>  BM.c_choronym_code AS &#x27;郡望&#x27;,<br>  BM.c_index_addr_id AS &#x27;地址ID&#x27;,<br>  PTOD.c_office_id AS &#x27;官署ID&#x27;,<br>  PTOD.c_posting_id AS &#x27;官职ID&#x27;,<br>  ED.c_entry_code AS &#x27;入仕方式代码&#x27;,<br>  ED.c_exam_rank AS &#x27;考试名次&#x27;,<br>  ED.c_age AS &#x27;入仕时的年龄&#x27;<br>FROM BIOG_MAIN BM<br>JOIN ENTRY_DATA ED ON BM.c_personid = ED.c_personid<br>JOIN POSTED_TO_OFFICE_DATA PTOD ON BM.c_personid = PTOD.c_personid;<br></code></pre></td></tr></table></figure>
<ul>
<li>
<p>对于朝代数据中的缺失值，我们选择填充默认值“19”，因为此朝代在数据表中出现了22万次，是众数。这一策略有助于维持数据的连贯性，同时避免了因缺失值过多而导致的信息丢失。<img src="/images/image-20240326230505887.png" srcset="/img/loading.gif" lazyload alt="image-20240326230505887"></p>
</li>
<li>
<p>鉴于地址数据中存在大量的缺省值，我们决定删除所有含有缺省地址的记录。这一做法旨在确保模型训练使用的数据具有较高的完整性和可用性。</p>
<p><img src="/images/image-20240326233039131.png" srcset="/img/loading.gif" lazyload alt="image-20240326233039131"></p>
</li>
<li>
<p>考虑到官职官署ID字段中“0”表示未入仕，而非“0”值表示已入仕，我们对该字段进行了二元编码，将所有“0”值标记为“未入仕”，其余值标记为“入仕”。然而，由于官职官署ID对于是否入仕的影响过于显著，可能导致模型过度依赖这一特征，我们选择从模型训练中删除该特征，以促使模型更多地关注其他特征，并提高模型对于数据的综合分析能力。</p>
</li>
</ul>
<p>在&quot;结果表.csv&quot;中删除第七列第八列</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs routeros">import pandas as pd<br><br><span class="hljs-comment"># 读取CSV文件</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;结果表.csv&#x27;</span>)<br><br><span class="hljs-comment"># 获取第七列和第八列的列名</span><br>col_to_drop_1 = df.columns[6]  <br>col_to_drop_2 = df.columns[7]  <br><br><span class="hljs-comment"># 删除指定的列</span><br>df.drop(columns=[col_to_drop_1, col_to_drop_2], <span class="hljs-attribute">inplace</span>=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 保存修改后的DataFrame到新的CSV文件</span><br>df.to_csv(<span class="hljs-string">&#x27;修改后的_结果表.csv&#x27;</span>, <span class="hljs-attribute">index</span>=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<p>为了更好地理解数据集的分布特征和数值范围，我们计算了数据的描述性统计量。描述性统计量是数据分析中的基础工具，它能够提供数据集的中心趋势、离散程度、分布形状等重要信息。我们使用<code>describe()</code>函数来计算数据集的均值、标准差、最小值、四分位数等统计量，这些统计量对于初步了解数据特征至关重要。</p>
<figure class="highlight coffeescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs coffeescript"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># 读取数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;结果表.csv&#x27;</span>) <br><br><span class="hljs-comment"># 计算描述性统计量</span><br>summary = df.describe()<br><br><span class="hljs-comment"># 计算标准差</span><br>summary[<span class="hljs-string">&#x27;std&#x27;</span>] = df.std()<br><br><span class="hljs-comment"># 显示描述性统计量</span><br><span class="hljs-built_in">print</span>(summary)<br><br><br>summary.to_csv(<span class="hljs-string">&#x27;data_summary.csv&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h4 id="如何对数据进行探索性数据分析（EDA）">如何对数据进行探索性数据分析（EDA）</h4>
<p>探索性数据分析（EDA）是一个数据分析流程，用于总结数据集的主要特征，通常使用可视化方法。以下是进行EDA的一般步骤和常用方法：</p>
<ol>
<li><strong>初步检查</strong>：
<ul>
<li><strong>数据加载</strong>：使用如 Pandas 的库将数据导入工具中。</li>
<li><strong>数据结构查看</strong>：了解数据的基本结构、行列数量以及数据类型。</li>
<li><strong>数据摘要</strong>：通过描述性统计（如均值、中位数、标准差、最小值、最大值）来摘要数据特征。</li>
<li><strong>检查缺失值</strong>：标识数据中的缺失值并考虑如何处理它们（例如，删除、填充或插值）。</li>
</ul>
</li>
<li><strong>单变量分析</strong>：
<ul>
<li>对于<strong>定量变量</strong>，利用箱型图、直方图、核密度估计图来了解分布。</li>
<li>对于<strong>定性变量</strong>，利用条形图来查看类别计数和比例。</li>
</ul>
</li>
<li><strong>多变量分析</strong>：
<ul>
<li><strong>数值型与数值型</strong>：散点图、线性关系图（对于两个连续变量之间的关系），热力图或相关矩阵（多个连续变量之间的相关性分析）。</li>
<li><strong>数值型与分类型</strong>：箱型图或小提琴图（了解类别对数值型变量分布的影响）。</li>
<li><strong>分类型与分类型</strong>：堆叠条形图或马赛克图（了解类别间的关系）。</li>
</ul>
</li>
<li><strong>组合特征</strong>：
<ul>
<li><strong>特征工程</strong>：基于现有数据创建新特征，以提高后续模型的预测性能。</li>
<li><strong>降维分析</strong>：如 PCA 或 t-SNE，以帮助理解数据结构，尤其在多维数据情况下。</li>
</ul>
</li>
<li><strong>异常检测</strong>：
<ul>
<li><strong>识别异常值</strong>：使用 Z 分数、IQR 范围等方法识别数据中的异常值。</li>
</ul>
</li>
<li><strong>数据预处理</strong>：
<ul>
<li><strong>数据清洗</strong>：根据EDA找到的问题处理数据，例如处理缺失值、异常值、错误数据等。</li>
</ul>
</li>
<li><strong>可视化工具选用</strong>：
<ul>
<li>Python 中 Matplotlib、Seaborn、Plotly 等库。</li>
<li>R 语言中的 ggplot2、lattice 等库。</li>
<li>使用 Tableau、Power BI 等商业工具。</li>
</ul>
</li>
<li><strong>总结得出结论</strong>：
<ul>
<li><strong>提炼见解</strong>：基于以上分析对数据集达到更深的理解。</li>
<li><strong>报告编写</strong>：记录分析过程中的发现，包括图形、统计结论等内容。</li>
</ul>
</li>
</ol>
<p>在整个EDA过程中，要特别注意数据的分布、模式和任何潜在的异常情况。EDA不仅能帮助我们理解数据，还能指导我们后续的数据预处理和模型构建策略。</p>
<h4 id="数据转换">数据转换</h4>
<p>​	为了增强地址信息的相关性，我们将地址ID替换为对应的省ID。这一转换使得模型能够更准确地捕捉到地理位置信息对于历史人物是否入仕的影响。</p>
<h5 id="标签编码">标签编码</h5>
<p>标签编码（Label Encoding）是一种将分类变量的每个类别映射到一个唯一的整数的方法。如果<code>ADDRESSES</code>表中的<code>c_addr_id</code>是地址的主键，而<code>belongs2_ID</code>表示省会ID，可以使用<code>belongs2_ID</code>来进行标签编码，因为它代表了地址的高层级分类。</p>
<h5 id="数据准备">数据准备</h5>
<p>确保<code>ADDRESSES</code>表中的<code>belongs2_ID</code>列包含了所有唯一的省会ID。这些ID应该是文本类型的，代表省会的名称或代码。</p>
<h5 id="创建映射字典">创建映射字典</h5>
<p>在Python中，您可以创建一个字典来映射每个省会ID到一个整数。通常，可以将最频繁出现的类别映射到0，然后按频率或其他逻辑顺序映射其余的类别。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># df是包含ADDRESSES表数据的DataFrame</span><br>df = pd.read_sql_table(<span class="hljs-string">&#x27;ADDRESSES&#x27;</span>, <span class="hljs-string">&#x27;数据库连接信息&#x27;</span>)<br><br><span class="hljs-comment"># 找到所有唯一的省会ID</span><br>province_ids = df[<span class="hljs-string">&#x27;belongs2_ID&#x27;</span>].unique()<br><br><span class="hljs-comment"># 创建一个映射字典，将省会ID映射到整数</span><br>mapping_dict = &#123;province_id: index <span class="hljs-keyword">for</span> index, province_id <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(province_ids)&#125;<br></code></pre></td></tr></table></figure>
<h5 id="应用标签编码">应用标签编码</h5>
<p>使用映射字典将<code>belongs2_ID</code>列中的每个省会ID映射到一个整数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 应用映射，创建一个新的列&#x27;province编码&#x27;</span><br>df[<span class="hljs-string">&#x27;province编码&#x27;</span>] = df[<span class="hljs-string">&#x27;belongs2_ID&#x27;</span>].<span class="hljs-built_in">map</span>(mapping_dict)<br></code></pre></td></tr></table></figure>
<h5 id="标签编码有点麻烦">标签编码有点麻烦</h5>
<p>直接把ADDRESSES表中的c_addr_id和belongs2_ID取出</p>
<p><code>SELECT c_addr_id, belongs2_ID FROM ADDRESSES;</code></p>
<p>生成CSV</p>
<p>把&quot;结果表.csv&quot;中的第六列（即地址ID）按照值替换为”test.csv“表中的地址ID（即第一列）的对应belongs2_ID（即第二列）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># 读取结果表.csv文件</span><br>results_df = pd.read_csv(<span class="hljs-string">&#x27;结果表.csv&#x27;</span>)<br><span class="hljs-comment"># 读取test.csv文件</span><br>test_df = pd.read_csv(<span class="hljs-string">&#x27;test.csv&#x27;</span>)<br><br><span class="hljs-comment"># 创建一个字典来映射地址ID到belongs2_ID</span><br>address_mapping = test_df.set_index(<span class="hljs-string">&#x27;地址ID&#x27;</span>)[<span class="hljs-string">&#x27;belongs2_ID&#x27;</span>].to_dict()<br><br><span class="hljs-comment"># 确保结果表中有一个名为&#x27;地址ID&#x27;的列</span><br>column_name = <span class="hljs-string">&#x27;地址ID&#x27;</span><br><span class="hljs-keyword">if</span> column_name <span class="hljs-keyword">in</span> results_df.columns:<br>    <span class="hljs-comment"># 替换操作</span><br>    results_df[column_name] = results_df[column_name].apply(<span class="hljs-keyword">lambda</span> x: address_mapping.get(x, x))<br><span class="hljs-keyword">else</span>:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;列名&#x27;<span class="hljs-subst">&#123;column_name&#125;</span>&#x27;在结果表中不存在。&quot;</span>)<br><br><span class="hljs-comment"># 保存修改后的DataFrame到新的CSV文件</span><br>results_df.to_csv(<span class="hljs-string">&#x27;修改后的结果表.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure>
<h4 id="数据标准-归一化">数据标准/归一化</h4>
<p>使用<code>StandardScaler</code>来标准化数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># 加载数据</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;标准化后的数据集.csv&#x27;</span>)<br><br><span class="hljs-comment"># 假设以下列包含连续变量，需要标准化</span><br>continuous_cols = [<span class="hljs-string">&#x27;所属户籍代码&#x27;</span>, <span class="hljs-string">&#x27;朝代&#x27;</span>, <span class="hljs-string">&#x27;地址ID&#x27;</span>, <span class="hljs-string">&#x27;入仕方式代码&#x27;</span>]<br><br><span class="hljs-comment"># 初始化标准化器</span><br>scaler = StandardScaler()<br><br><span class="hljs-comment"># 对连续变量进行标准化</span><br>df[continuous_cols] = scaler.fit_transform(df[continuous_cols])<br><br><br><span class="hljs-comment"># 首先，计算第六列的均值，假设第六列的列名为&#x27;地址ID&#x27;</span><br>mean_address_id = df[<span class="hljs-string">&#x27;地址ID&#x27;</span>].mean()<br><br><span class="hljs-comment"># 然后，使用fillna方法填充空值，其中ax=0表示按行填充（即将每行的空值都填充为均值）</span><br>df[<span class="hljs-string">&#x27;地址ID&#x27;</span>].fillna(mean_address_id, inplace=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 保存标准化后的数据集</span><br>df.to_csv(<span class="hljs-string">&#x27;标准化后的数据集1.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br><br><br></code></pre></td></tr></table></figure>
<h4 id="标签制作">标签制作</h4>
<p>在”结果表.csv“的最后新建一个Has_Office_ID列，这个列在官署ID（第七列）与官职ID（第八列）同时为0的时候赋值为0，即未入仕</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># 加载CSV文件</span><br>file_path = <span class="hljs-string">&#x27;修改后的结果表.csv&#x27;</span><br>df = pd.read_csv(file_path)<br><br><span class="hljs-comment"># 删除最后1列</span><br><span class="hljs-comment"># df = df.iloc[:, :-1]</span><br><br><span class="hljs-comment"># 删除第7列和第8列</span><br>df.drop(df.columns[[<span class="hljs-number">6</span>, <span class="hljs-number">7</span>]], axis=<span class="hljs-number">1</span>, inplace=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 保存修改后的DataFrame到新的CSV文件</span><br>df.to_csv(<span class="hljs-string">&#x27;修改后的结果表1.csv&#x27;</span>, index=<span class="hljs-literal">False</span>)<br><br><span class="hljs-comment"># # 新建&#x27;Has_Office_ID&#x27;列，根据&#x27;官署ID&#x27;和&#x27;官职ID&#x27;列检查是否为空（NaN）</span><br><span class="hljs-comment"># # 如果两者至少有一个是空，&#x27;Has_Office_ID&#x27;为0，否则为1</span><br><span class="hljs-comment"># df[&#x27;Has_Office_ID&#x27;] = ((~df.iloc[:, 6].isna()) &amp; (~df.iloc[:, 7].isna())).astype(int)</span><br><br><span class="hljs-comment"># # 将新数据保存到原始CSV文件（或者保存为新的文件）</span><br><span class="hljs-comment"># df.to_csv(file_path, index=False)</span><br><br><span class="hljs-comment"># print(f&quot;&#x27;Has_Office_ID&#x27;列已添加到 &#x27;&#123;file_path&#125;&#x27;&quot;)</span><br><br><br></code></pre></td></tr></table></figure>
<h3 id="模型训练">模型训练</h3>
<p><strong>模型选择</strong>：</p>
<ul>
<li><strong>逻辑回归</strong>：作为二分类问题的基础模型，逻辑回归是一个很好的起点。它简单、易于实现，并且可以给出特征的权重，帮助理解哪些特征对预测结果影响较大。</li>
<li><strong>决策树/随机森林</strong>：决策树模型易于理解，可以处理分类和数值特征，随机森林作为集成学习的一种，通常能提供更好的性能。</li>
<li><strong>梯度提升机（GBM）</strong>：GBM是另一种强大的集成学习方法，对于许多分类问题都能取得很好的效果。</li>
<li><strong>支持向量机（SVM）</strong>：SVM在特征维度较高时表现良好，可以尝试用于此任务。</li>
<li><strong>神经网络</strong>：如果数据集足够大，也可以尝试使用简单的神经网络模型，如多层感知机（MLP）。</li>
</ul>
<p>最后选择LightGBM和随机森林</p>
<h5 id="随机森林：">随机森林：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, recall_score, precision_score, f1_score, confusion_matrix<br><br><span class="hljs-comment"># 读取CSV文件</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;标准化后的数据集1.csv&#x27;</span>)<br><br><span class="hljs-comment"># 定义特征和目标变量</span><br>X = df.drop([<span class="hljs-string">&#x27;个人ID&#x27;</span>, <span class="hljs-string">&#x27;Has_Office_ID&#x27;</span>], axis=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 去除个人ID和目标变量</span><br>y = df[<span class="hljs-string">&#x27;Has_Office_ID&#x27;</span>]<br><br><span class="hljs-comment"># 分割数据集为训练集和测试集</span><br>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>, random_state=<span class="hljs-number">42</span>, stratify=y)<br><br><span class="hljs-comment"># 归一化特征</span><br>scaler = StandardScaler()<br>X_train = scaler.fit_transform(X_train)<br>X_test = scaler.transform(X_test)<br><br><span class="hljs-comment"># 创建Random Forest模型</span><br>model = RandomForestClassifier(n_estimators=<span class="hljs-number">100</span>, random_state=<span class="hljs-number">42</span>)  <span class="hljs-comment"># n_estimators是树的数量</span><br><span class="hljs-comment"># 训练模型</span><br>model.fit(X_train, y_train)<br><br><span class="hljs-comment"># 进行预测</span><br>y_pred = model.predict(X_test)<br><br><span class="hljs-comment"># 计算性能指标</span><br>accuracy = accuracy_score(y_test, y_pred)<br>recall = recall_score(y_test, y_pred)<br>precision = precision_score(y_test, y_pred)<br>f1 = f1_score(y_test, y_pred)<br>conf_matrix = confusion_matrix(y_test, y_pred)<br><br><span class="hljs-comment"># 打印性能指标</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy: <span class="hljs-subst">&#123;accuracy&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Recall: <span class="hljs-subst">&#123;recall&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Precision: <span class="hljs-subst">&#123;precision&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;F1 Score: <span class="hljs-subst">&#123;f1&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Confusion Matrix:\n<span class="hljs-subst">&#123;conf_matrix&#125;</span>&#x27;</span>)<br></code></pre></td></tr></table></figure>
<h5 id="lightbgm：">lightbgm：</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> lightgbm <span class="hljs-keyword">as</span> lgb<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> StratifiedShuffleSplit<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, roc_auc_score<br><span class="hljs-keyword">from</span> lightgbm <span class="hljs-keyword">import</span> train <span class="hljs-keyword">as</span> lgb_train<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score, roc_auc_score, f1_score<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_score, recall_score, confusion_matrix<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve, precision_recall_curve<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> matthews_corrcoef<br><br><br><span class="hljs-comment"># 读取数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;标准化后的数据集1.csv&#x27;</span>)<br><br><span class="hljs-comment"># 定义特征列和目标列</span><br>features = df.columns.difference([<span class="hljs-string">&#x27;Has_Office_ID&#x27;</span>])<br>target = <span class="hljs-string">&#x27;Has_Office_ID&#x27;</span><br><br><span class="hljs-comment"># 划分数据集为训练集和测试集，进行分层抽样</span><br>sss = StratifiedShuffleSplit(n_splits=<span class="hljs-number">1</span>, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>)<br><span class="hljs-keyword">for</span> train_index, test_index <span class="hljs-keyword">in</span> sss.split(df[features], df[target]):<br>    X_train, X_test = df[features].iloc[train_index], df[features].iloc[test_index]<br>    y_train, y_test = df[target].iloc[train_index], df[target].iloc[test_index]<br><br><span class="hljs-comment"># 创建训练和测试数据集</span><br>train_data = lgb.Dataset(X_train, label=y_train)<br>test_data = lgb.Dataset(X_test, label=y_test)<br><span class="hljs-comment"># lgb.__dict__[&#x27;train&#x27;]</span><br><span class="hljs-comment"># 设置LightGBM的参数</span><br>params = &#123;<br>    <span class="hljs-string">&#x27;objective&#x27;</span>: <span class="hljs-string">&#x27;binary&#x27;</span>,  <span class="hljs-comment"># 二分类任务</span><br>    <span class="hljs-string">&#x27;boosting_type&#x27;</span>: <span class="hljs-string">&#x27;gbdt&#x27;</span>,  <span class="hljs-comment"># 使用GBDT</span><br>    <span class="hljs-string">&#x27;metric&#x27;</span>: <span class="hljs-string">&#x27;auc&#x27;</span>,  <span class="hljs-comment"># 使用AUC作为评估指标</span><br>    <span class="hljs-string">&#x27;num_leaves&#x27;</span>: <span class="hljs-number">31</span>,  <span class="hljs-comment"># 树的最大深度</span><br>    <span class="hljs-string">&#x27;learning_rate&#x27;</span>: <span class="hljs-number">0.05</span>,  <span class="hljs-comment"># 学习率</span><br>    <span class="hljs-string">&#x27;feature_fraction&#x27;</span>: <span class="hljs-number">0.9</span>,  <span class="hljs-comment"># 特征随机选择比例</span><br>    <span class="hljs-string">&#x27;bagging_fraction&#x27;</span>: <span class="hljs-number">0.8</span>,  <span class="hljs-comment"># 子采样比例</span><br>    <span class="hljs-string">&#x27;reg_lambda&#x27;</span>: <span class="hljs-number">0.5</span>,  <span class="hljs-comment"># L2正则化系数</span><br>    <span class="hljs-string">&#x27;verbose&#x27;</span>: <span class="hljs-number">1</span>,  <span class="hljs-comment"># 输出详细信息</span><br>&#125;<br><br><span class="hljs-comment"># 在GPU上训练模型</span><br>params[<span class="hljs-string">&#x27;device&#x27;</span>] = <span class="hljs-string">&#x27;gpu&#x27;</span>  <span class="hljs-comment"># 指定使用GPU</span><br>params[<span class="hljs-string">&#x27;gpu_platform_id&#x27;</span>] = <span class="hljs-number">0</span>  <span class="hljs-comment"># GPU的平台ID，通常是0</span><br>params[<span class="hljs-string">&#x27;gpu_device_id&#x27;</span>] = <span class="hljs-number">0</span>  <span class="hljs-comment"># GPU的设备ID，通常是0</span><br><br><span class="hljs-comment"># 创建模型</span><br>gbm = lgb_train(<br>    params,<br>    train_data,<br>    num_boost_round=<span class="hljs-number">1000</span>,<br>    valid_sets=[test_data]<br>    <span class="hljs-comment"># early_stopping_rounds=10</span><br>)<br><br><span class="hljs-comment"># 预测测试集</span><br>y_pred = gbm.predict(X_test)  <span class="hljs-comment"># 使用测试特征进行预测</span><br>y_pred_label = [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> x &gt; <span class="hljs-number">0.5</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> y_pred]  <span class="hljs-comment"># 应用阈值进行分类</span><br><br><br><span class="hljs-comment"># 计算评估指标</span><br>accuracy = accuracy_score(y_test, y_pred_label)<br>roc_auc = roc_auc_score(y_test, y_pred)<br><br><br><span class="hljs-comment"># 输出评估结果</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Accuracy: <span class="hljs-subst">&#123;accuracy&#125;</span>&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;ROC AUC Score: <span class="hljs-subst">&#123;roc_auc&#125;</span>&#x27;</span>)<br><br><br></code></pre></td></tr></table></figure>
<p>生成日志：</p>
<ol>
<li><strong>Number of positive: 50120, number of negative: 139056</strong>: 这表示在你的数据集中，有50120个正样本（即<code>Has_Office_ID</code>为1的样本）和139056个负样本（即<code>Has_Office_ID</code>为0的样本）。这反映了你的数据集是不平衡的，有更多的样本属于负类。</li>
<li><strong>This is the GPU trainer!!</strong>: 这表明你正在使用GPU训练器。使用GPU可以显著加快模型的训练速度，特别是在处理大型数据集时。</li>
<li><strong>Total Bins 786</strong>: 这是在训练过程中创建的直方图桶（histogram bins）的总数。直方图桶是<code>LightGBM</code>用于提高训练效率和性能的一种技术。</li>
<li><strong>Number of data points in the train set: 189176, number of used features: 7</strong>: 这表示训练集中总共有189176个数据点，并且有7个特征被用于训练。</li>
<li><strong>Using requested OpenCL platform 0 device 0</strong>: 这表明<code>LightGBM</code>正在使用请求的OpenCL平台0上的设备0进行训练。</li>
<li><strong>Using GPU Device: NVIDIA GeForce RTX 3070 Laptop GPU, Vendor: NVIDIA Corporation</strong>: 这显示了正在使用的GPU设备是NVIDIA GeForce RTX 3070笔记本电脑GPU，由NVIDIA公司制造。</li>
<li><strong>Compiling OpenCL Kernel with 256 bins…</strong>: 这是<code>LightGBM</code>在编译OpenCL内核，其中包含256个直方图桶。</li>
<li><strong>GPU programs have been built</strong>: 这表明GPU程序已经构建完成。</li>
<li><strong>Size of histogram bin entry: 8</strong>: 这是直方图桶条目的大小，单位是字节。</li>
<li><strong>4 dense feature groups (0.72 MB) transferred to GPU in 0.002099 secs. 1 sparse feature groups</strong>: 这表示有4个密集特征组（大小约为0.72MB）在0.002099秒内被传输到GPU，并且还有1个稀疏特征组。</li>
<li><strong>[binary:BoostFromScore]: pavg=0.264938 -&gt; initscore=-1.020457</strong>: 这是二元分类的BoostFromScore策略，其中<code>pavg</code>是平均概率，<code>initscore</code>是初始化分数。这个策略用于在训练开始之前为每个类别分配一个初始分数，以便在训练过程中进行提升。</li>
<li><strong>Start training from score -1.020457</strong>: 这是训练开始时的初始分数，这个分数会在每一轮提升中被更新。</li>
</ol>
<p>Matthews Correlation Coefficient (MCC) 是一个用于衡量分类模型性能的指标，特别是在二分类和多分类问题中。MCC 考虑了所有四个可能的混淆矩阵的值：真正例（TP）、假正例（FP）、真负例（TN）和假负例（FN），并提供了一个介于-1和1之间的值，其中1表示完美的分类，0表示随机分类，负值表示模型的表现比随机分类还差。</p>
<h3 id="模型优化">模型优化</h3>
<p>数据集出现类别分布不平衡时，意味着某个类别的样本数远远多于其他类别。这在现实世界中很常见，例如在欺诈检测或疾病诊断的数据集中，不平衡数据集很容易导致算法过于偏向多数类，从而忽略那些更少见但通常更为重要的异常情况。以下是几种常用的处理数据不平衡的技术：</p>
<h4 id="过采样（Oversampling）">过采样（Oversampling）</h4>
<p>简而言之，过采样增加了少数类的样本数量。一种做法是简单地复制已有的少数类样本，这种方法称为随机过采样。</p>
<p>但过度复制可能导致过拟合，因此更好的做法通常是使用更智能的过采样方法，如SMOTE（合成少数类过采样技术）。SMOTE通过对少数类样本进行分析并合成新样本来增加少数类的代表性。</p>
<h4 id="欠采样（Undersampling）">欠采样（Undersampling）</h4>
<p>欠采样则是减少多数类的样本数量。与随机过采样一样，您可以随机地舍弃一些多数类样本，但这可能会丢失重要信息。有些技术，比如集群分析方法，可以帮助在减少样本数量的同时保留多数类的重要信息。</p>
<h4 id="SMOTE（合成少数类过采样技术）">SMOTE（合成少数类过采样技术）</h4>
<p>SMOTE是一种受欢迎的过采样方法，它通过在少数类样本之间插值来合成新的例子。它选择两个或多个相似的少数类样本（通常使用欧氏距离）并在它们之间随机创建新样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.impute <span class="hljs-keyword">import</span> SimpleImputer<br><span class="hljs-keyword">from</span> imblearn.over_sampling <span class="hljs-keyword">import</span> SMOTE<br><br><span class="hljs-comment"># 读取数据集</span><br>df = pd.read_csv(<span class="hljs-string">&#x27;标准化后的数据集1.csv&#x27;</span>)<br><br><span class="hljs-comment"># 定义特征和目标变量</span><br>X = df.drop([<span class="hljs-string">&#x27;个人ID&#x27;</span>, <span class="hljs-string">&#x27;Has_Office_ID&#x27;</span>], axis=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 移除非特征列</span><br>y = df[<span class="hljs-string">&#x27;Has_Office_ID&#x27;</span>]<br><br><span class="hljs-comment"># 处理缺失值（这里使用中位数填充）</span><br>imputer = SimpleImputer(missing_values=np.nan, strategy=<span class="hljs-string">&#x27;median&#x27;</span>)<br>X_imputed = imputer.fit_transform(X)<br><br><span class="hljs-comment"># 数据划分</span><br>X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=<span class="hljs-number">0.3</span>, random_state=<span class="hljs-number">42</span>, stratify=y)<br><br><span class="hljs-comment"># 过采样</span><br>smote = SMOTE(random_state=<span class="hljs-number">42</span>)<br>X_resampled, y_resampled = smote.fit_resample(X_train, y_train)<br><br><span class="hljs-comment"># X_resampled和y_resampled是经过SMOTE处理后的数据，可用于模型训练</span><br></code></pre></td></tr></table></figure>
<p>但表现更差，放弃</p>
<h3 id="遇到bug">遇到bug</h3>
<p>Traceback (most recent call last):  File “c:\Users\14097\Desktop\ABDAF\Train.py”, line 42, in <module>    gbm = lgb.train( TypeError: train() got an unexpected keyword argument ‘early_stopping_rounds’</p>
<p>从您提供的错误信息来看，<code>lightgbm.train</code>函数不应该出现对<code>early_stopping_rounds</code>参数的不识别。这个参数是有效的，并且通常用于<code>train</code>函数中。一种可能性是您可能没有使用LightGBM的函数，而是重定义了一个名为<code>lgb</code>的变量，该变量的<code>train</code>方法不支持这个参数。</p>
<p>您的代码看起来在概念上是正确的，<code>early_stopping_rounds</code>是<code>train</code>函数的合法参数。如果您遇到<code>lightgbm.train()</code>不接受<code>early_stopping_rounds</code>的问题，可能是以下几个原因：</p>
<ol>
<li>您当前的工作环境可能存在多个版本的LightGBM安装，而且您可能不小心使用了旧版本的API。</li>
<li>您的Python环境中可能有另一个名为<code>lgb</code>的模块或包与<code>lightgbm</code>库的名称冲突。</li>
<li>您的LightGBM安装可能存在问题。</li>
</ol>
<p>早停(strict early stopping)是用于防止模型过拟合的一种方式，其工作原理是如果连续一定轮数（您设定的早停轮数）模型的验证集误差没有改善，那么就停止训练。但是，这并不是必须的，只是在某些情况下可以帮助提高模型的泛化能力。</p>
<p>更新重装改正都没用，所以只能把<code>early_stopping_rounds</code>参数删掉，所以有可能过拟合了</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E6%95%B0%E6%8D%AE%E5%BB%BA%E6%A8%A1/" class="category-chain-item">数据建模</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>基于中國歷代人物傳記資料庫(CBDB)的数据分析与挖掘</div>
      <div>http://example.com/2024/03/27/ABDAF/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>LT</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年3月27日</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>更新于</div>
          <div>2024年3月27日</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/03/21/CNNGraduationProject/" title="一天速做CNN毕设">
                        <span class="hidden-mobile">一天速做CNN毕设</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.16/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"HkXo4YrF9gS9RozMLHhRxbGJ-gzGzoHsz","appKey":"zsnDvCeWpb7b2pwY0DsWlbbj","path":"window.location.pathname","placeholder":"欢迎留下您的评论","avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":true,"recordIP":true,"serverURLs":"https://hkxo4yrf.lc-cn-n1-shared.com","emojiCDN":"https://img.t.sinajs.cn/t4/appstyle/expression/ext/normal/","emojiMaps":null,"enableQQ":true},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a target="_blank" rel="noopener" href="https://clustrmaps.com/site/1byz6"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=39UOFU0-uCK0cGaFhqApnRGLelojEfT2igoF5yuClko&cl=ffffff" srcset="/img/loading.gif" lazyload /></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
    <!-- 备案信息 ICP for China -->
    <div class="beian">
  <span>
    <a href="http://beian.miit.gov.cn/" target="_blank" rel="nofollow noopener">
      鲁ICP备2022016408号
    </a>
  </span>
  
</div>

  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.0/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
